# Classificador de Imagens: Pessoa vs. Cavalo

Este projeto visa desenvolver um modelo de Machine Learning capaz de classificar imagens como "Pessoa" ou "Cavalo", utilizando t√©cnicas avan√ßadas de Vis√£o Computacional a partir de Redes Neurais Convolucionais.

## üì¶ Arquivos
  Neste reposit√≥rio est√£o presentes os arquivos:
  * horse-or-human: Dataset para treino;
  * validation-horse-or-human: Dataset para valida√ß√£o;
  * model: Diret√≥rio contendo o modelo;
  * metrics_results: Gr√°ficos para an√°lise do modelo;
  * validation_results: Imagens de valida√ß√£o com a predi√ß√£o do modelo;
  * data_loader.py: M√≥dulo para carregamento do dataset;
  * train.py: C√≥digo de treinamento do modelo;
  * validate_model.py: Analisa as predi√ß√µes do modelo com o dataset de valida√ß√£o e salva imagens em validation_results;
  * inference_api.py: API para realizar predi√ß√µes em tempo real.
    
## üìã Justificativa das Escolhas T√©cnicas
1. Arquitetura do Modelo:
   
  Para a constru√ß√£o do modelo de classifica√ß√£o, a escolha foi baseada na t√©cnica de Transfer Learning utilizando a arquitetura MobileNetV2. Essa t√©cnica √© muito eficiente pois o MobileNetV2 (modelo conhecido por sua capacidade de classifica√ß√£o) j√° foi pr√©-treinado em um vasto conjunto de dados (ImageNet), aprendendo a reconhecer caracter√≠sticas visuais gen√©ricas. Ao "congelar" as camadas convolucionais desse modelo e adicionar novas camadas de classifica√ß√£o, o modelo √© capaz de aprender a distinguir as classes de interesse de forma mais r√°pida e eficiente. Para a implementa√ß√£o do modelo foi usado o TensorFlow com sua API de alto n√≠vel, o Keras.

2. Camadas do Modelo: 
   ```
   x = base_model.output
   x = GlobalAveragePooling2D()(x)
   x = Dense(128, activation='relu')(x)
   x = Dropout(0.3)(x)
   predictions = Dense(1, activation='sigmoid')(x)
   ```
  A base do MobileNetV2 atua como um extrator de caracter√≠sticas. Em seguida foi criado a estrutura:
  * GlobalAveragePooling2D: Calcula a m√©dia de cada mapa de caracter√≠sticas da imagem at√© que cada dimens√£o espacial seja 1 (faz um resumo da imagem).
  * Dense: Recebe o resumo da imagem e procura por padr√µes espec√≠ficos que ajudem a diferenciar entre as classes. O n√∫mero 128 representa a quantidade de neur√¥nios e a fun√ß√£o 'relu' permite que o modelo aprenda rela√ß√µes n√£o lineares e mais complexas na imagem.
  * Dropout: T√©cnica para evitar overfitting, desativa aleatoriamente 30% dos neur√¥nios da camada anterior.
  * Dense: Camada de sa√≠da, recebe os padr√µes finais e toma a decis√£o. A fun√ß√£o 'sigmoid' transforma a sa√≠da do neur√¥nio em um valor entre 0 e 1 que significa a probabilidade de ser um humano na imagem.
3. Regra de Decis√£o: 
  * Se a sa√≠da for maior que 0.5, a classe predita √© Pessoa.
  * Se a sa√≠da for menor ou igual a 0.5, a classe predita √© Cavalo.
4. Fun√ß√£o Objetivo e Otimizador
  * Fun√ß√£o Objetivo (loss): 'binary_crossentropy' foi escolhida por ser a fun√ß√£o de perda padr√£o e mais adequada para problemas de classifica√ß√£o bin√°ria.
  * Otimizador: Adam com um learning_rate de 1e-4 foi utilizado pois evita grandes altera√ß√µes nos pesos das camadas, mantendo o conhecimento pr√©-adquirido.
5. Estrat√©gia de Valida√ß√£o e Treinamento
  * Data Augmentation: Para evitar overfitting e aumentar a quantidade de dados de treino, a t√©cnica de data augmentation foi empregada com ImageDataGenerator.
  * Early Stopping: Para garantir que o modelo n√£o treine mais do que o necess√°rio e comece a ter overfitting, um callback de EarlyStopping foi implementado. Ele monitora a perda de valida√ß√£o (val_loss) e para o treinamento se n√£o houver melhora por 5 √©pocas.

## üíª Instru√ß√µes para Setup e Execu√ß√£o
  * Pr√©-requisitos: Python3.8+ (foi usado o Python3.10) e Pip
1. Clonar o reposit√≥rio:
   ```
   git clone https://github.com/mandamattosg/Classification-Model.git
   cd Classification-Model
   ```
2. Instalar depend√™ncias:
    ```
    python -m venv venv
    source venv/bin/activate  # No Windows use `venv\Scripts\activate`
    pip install -r requirements.txt
   ```
3. Treinamento do modelo:
    ```
    python train.py
   ```
4. Valida√ß√£o do modelo:
   
   Para visualizar as predi√ß√µes do modelo no dataset de valida√ß√£o:
    ```
    python validate_model.py
   ```
6. Execu√ß√£o da API de Infer√™ncia:
   A API exp√µe um √∫nico endpoint para realizar a infer√™ncia.
  * Endpoint: /predict
  * M√©todo: POST
  * Formato da Imagem: A imagem deve ser enviada como um arquivo no corpo da requisi√ß√£o, utilizando o formato multipart/form-data.
    
   Para ativar o funcionamento da API REST:
   ```
   python -m uvicorn inference_api:app --reload
   ```
   Agora, voc√™ pode solicitar a infer√™ncia como preferir, por exemplo:
   * Usando CURL no CMD:
     ```
     curl -X POST "http://127.0.0.1:8000/predict" -F "file=@validation-horse-or-human/horses/horse1-000.png"
     ```
  * Usando CURL no Windows PowerShell:
      ```
     curl.exe -X POST "http://127.0.0.1:8000/predict" -F file=@'validation-horse-or-human/horses/horse1-000.png'
     ```
  Exemplo de resposta:

  A resposta √© um JSON constendo o texto da classifica√ß√£o e a confian√ßa da predi√ß√£o.
  ```
  {
  "prediction": "Is a horse",
  "confidence": 0.9987
  }
```

## üìà An√°lise de M√©tricas
Para entender e analisar a performance do modelo foram analisadas a Loss, Accuracy e Confusion Matrix que podem ser vistas abaixo. \
    <img width="400" height="300" alt="loss_plot" src="https://github.com/user-attachments/assets/82674523-957c-4807-aa27-e697218bdf8a" />
    <img width="400" height="300" alt="accuracy_plot" src="https://github.com/user-attachments/assets/88f2ba4f-8d17-4fd2-b423-8f11704303de" />
    <img width="400" height="300" alt="confusion_matrix" src="https://github.com/user-attachments/assets/abed2158-ce86-418a-97a1-f8abe7662736" />
    
Percebe-se que o mecanismo de Early Stopping encerrou o treinamento na √©poca n√∫mero 22. A loss de treino e valida√ß√£o diminui rapidamente nas primeiras √©pocas. Ambas as curvas de accuracy se estabilizam em um patamar alto (98.83%). J√° na matriz vemos que das 128 imagens de cavalos, o modelo acertou 127 e errou apenas 1, al√©m de ter acertado todas as previs√µes de humanos.
Esses resultados s√£o √≥timos e comprovam que o modelo √© capaz de diferenciar imagens de pessoas e cavalos.

Para ter ainda mais certeza da sua acur√°cia, atrav√©s do c√≥digo 'validate_model.py' √© poss√≠vel obter os resultados em uma pasta chamada 'validation_results' onde podemos analisar calmamente a predi√ß√£o de cada imagem do conjunto de dados de valida√ß√£o. Esse tipo de an√°lise √© interessante pois podemos identificar padr√µes nas imagens que o modelo teve mais dificuldade em classificar. Por exemplo,
nesse teste realizado, o modelo errou 3 classifica√ß√µes de cavalos, como pode ser visto nas imagens abaixo: \
<img width="281" height="366" alt="incorrect_horse6-161" src="https://github.com/user-attachments/assets/390efd7f-3b6d-4f3c-8814-01ff086d4aea" />
<img width="281" height="366" alt="incorrect_horse5-103" src="https://github.com/user-attachments/assets/44d2b2af-0108-4730-9d97-90ea4f1038ae" />
<img width="281" height="366" alt="incorrect_horse3-498" src="https://github.com/user-attachments/assets/766209ff-9ba5-4e88-bcce-d7f3272265c1" />

√â percept√≠vel que o modelo tem dificuldade para classificar imagens em que o cavalo est√° somente em 2 patas e/ou sua estrutura corporal n√£o est√° clara. Ainda assim, vale notar que sua acur√°cia chega a 98.83% representando um √≥timo desempenho geral, portanto, sim, o modelo atende e supera o problema proposto.

Para melhorias e pr√≥ximos passos √© poss√≠vel considerar:
* Fine-Tuning: Em vez de manter todas as camadas da base do MobileNetV2 congeladas, poder√≠amos descongelar as √∫ltimas camadas e trein√°-las com uma taxa de aprendizado muito baixa. Isso permitiria que o modelo se ajuste ainda mais √†s particularidades do dataset.
* Aumentar o Dataset: Adicionar mais dados ao conjunto de treino, provenientes de outras fontes, poderia tornar o modelo ainda mais robusto a varia√ß√µes de ilumina√ß√£o, pose e fundo.
* Deploy em Cloud: A API pode ser containerizada com Docker e implantada em servi√ßos de nuvem (AWS, GCP, Azure) para escalabilidade e disponibilidade em produ√ß√£o.
* Otimiza√ß√£o de Lat√™ncia: Para aplica√ß√µes em tempo real, seria poss√≠vel otimizar o modelo com t√©cnicas de quantiza√ß√£o usando TensorFlow Lite.

